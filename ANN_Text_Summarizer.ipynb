{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shaur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shaur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter url of the text you want to summerize: https://en.wikipedia.org/wiki/Main_Page\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The protective earth conductor may also be covered with insulation although in some countries this conductor may be left as bare copper. Each of the current carrying conductors in the core is insulated by an individual thermoplastic sheath coloured to indicate the purpose of the conductor concerned. The type of thermoplastic the dimensions of the conductors and the colour of their individual insulation are specified by the regulatory bodies in the various countries concerned. After the war he joined the Texas Air National Guard and participated in several air races. He is one of seven American pilots to have achieved ace status in two different wars. In 1965 he served in several command roles during the Vietnam War while flying 30 combat missions.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "import urllib.request as url\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "stop_word = stopwords.words('english')\n",
    "import string\n",
    "import heapq\n",
    "\n",
    "\n",
    "\n",
    "url_name = input(\"Enter url of the text you want to summerize:\")\n",
    "web = url.urlopen(url_name)\n",
    "page = bs4.BeautifulSoup(web,'html.parser')\n",
    "elements = page.find_all('p')\n",
    "article = ''\n",
    "for i in elements:\n",
    "    article+= (i.text)\n",
    "article\n",
    "processed = article.replace(r'^\\s+|\\s+?$','')\n",
    "processed = processed.replace('\\n',' ')\n",
    "\n",
    "processed = processed.replace(\"\\\\\",'')\n",
    "processed = processed.replace(\",\",'')\n",
    "processed = processed.replace('\"','')\n",
    "processed = re.sub(r'\\[[0-9]*\\]','',processed)\n",
    "processed\n",
    "\n",
    "\n",
    "sentences = sent_tokenize(processed)\n",
    "\n",
    "\n",
    "\n",
    "frequency = {}\n",
    "\n",
    "processed1 = processed.lower()\n",
    "\n",
    "for word in word_tokenize(processed1):\n",
    "\n",
    "    if word not in stop_word and word not in string.punctuation:\n",
    "\n",
    "        if word not in frequency.keys():\n",
    "\n",
    "            frequency[word]=1\n",
    "\n",
    "        else:\n",
    "\n",
    "            frequency[word]+=1\n",
    "\n",
    "frequency\n",
    "\n",
    "max_fre = max(frequency.values())\n",
    "\n",
    "for word in frequency.keys():\n",
    "\n",
    "    frequency[word]=(frequency[word]/max_fre)\n",
    "\n",
    "frequency\n",
    "sentence_score = {}\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    for word in word_tokenize(sent):\n",
    "\n",
    "     if word in frequency.keys():\n",
    "\n",
    "            if len(sent.split(' '))<30:\n",
    "\n",
    "                if sent not in sentence_score.keys():\n",
    "\n",
    "                    sentence_score[sent] = frequency[word]\n",
    "\n",
    "                else:\n",
    "                    sentence_score[sent]+=frequency[word]\n",
    "sentence_score\n",
    "\n",
    "\n",
    "\n",
    "summary = heapq.nlargest(6,sentence_score,key = sentence_score.get)\n",
    "\n",
    "summary = ' '.join(summary)\n",
    "\n",
    "summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
